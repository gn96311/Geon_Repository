{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDP",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "10ZR8tHxRG751AD5gVLd0JGmNW0r_0aDP",
      "authorship_tag": "ABX9TyOElgU7usCSNotcnfZ17gHX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gn96311/Geon_Repository/blob/master/IDP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOvc2NYfPP3y"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os, re, glob\n",
        "import time\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageMath\n",
        "from keras.preprocessing.image import load_img, array_to_img, img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import IPython.display as display"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKSsSsUqa2Kc"
      },
      "source": [
        "tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV5lcJazPqaH",
        "outputId": "b8be7357-e5d3-497f-e593-64d9721da390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Dataset_dir = os.getcwd() + '/drive/My Drive/Colab/Data'\n",
        "print(Dataset_dir)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab/Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzXPbFl5Jsvu"
      },
      "source": [
        "# Image to Patches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHI5KyWCJz9p"
      },
      "source": [
        "def image_to_patches(img_pad, stride_x, stride_y, patch_shape = (32, 32), mini_batch_size = 256):\n",
        "    PATCH_SHAPE = patch_shape\n",
        "    H, W = img_pad.shape\n",
        "    batches = None\n",
        "\n",
        "    num_patches_x = (W - PATCH_SHAPE[1]) / stride_x + 1\n",
        "    num_patches_y = (H - PATCH_SHAPE[0]) / stride_y + 1\n",
        "\n",
        "    total_patches = int(num_patches_x * num_patches_y)\n",
        "    res = int(total_patches % mini_batch_size)\n",
        "\n",
        "    batches = np.zeros((total_patches, *PATCH_SHAPE))\n",
        "\n",
        "    x = y = 0\n",
        "    for n in range(total_patches):\n",
        "        patch = np.array([img_pad[y:y+PATCH_SHAPE[1], x:x+PATCH_SHAPE[0]]])\n",
        "        assert patch.shape == (1, *PATCH_SHAPE), \"Shape mismatch, %s\" % str(patch.shape)\n",
        "\n",
        "        batches[n, :, :] = patch\n",
        "\n",
        "        if x + PATCH_SHAPE[1] < W:\n",
        "            x += stride_x\n",
        "\n",
        "        elif x + PATCH_SHAPE[1] >= W and y + PATCH_SHAPE[0] < H:\n",
        "            y += stride_y\n",
        "            x = 0\n",
        "\n",
        "        elif x + PATCH_SHAPE[1] >= W and y + PATCH_SHAPE[0] >= H:\n",
        "            break\n",
        "\n",
        "    if not res == 0:\n",
        "        for i in range(mini_batch_size-res):\n",
        "            batches = np.concatenate((batches, patch), axis=0)\n",
        "\n",
        "    batches = batches.reshape(-1, mini_batch_size, PATCH_SHAPE[0], PATCH_SHAPE[1])\n",
        "\n",
        "    return batches, res"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOeMeDBVLllk"
      },
      "source": [
        "#img = Image.open(Dataset_dir + '/Mona.jpg')\n",
        "#img = np.asarray(img)\n",
        "#img = img[12:1068, 12:1068, :]\n",
        "#batches, res = image_to_patches(img, 16, 16)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPgQM9LRk9xb"
      },
      "source": [
        "# Save the patches into Folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VifEMpEjVoqN"
      },
      "source": [
        "class Dataset_maker():\n",
        "    def __init__(self, img_list, list_number, mode):\n",
        "        self.images_list = img_list\n",
        "        self.list_num = list_number\n",
        "        self.mode = mode\n",
        "        assert len(np.shape(self.images_list)) == 4, \"The shape of Image list is not 4D, this shape is {}\".format(len(np.shape(self.images_list)))\n",
        "        \n",
        "    def write_img(self):\n",
        "        list_num = (\"{}\".format(self.list_num)).zfill(3)\n",
        "        with tqdm(total = np.shape(self.images_list)[0] * (np.shape(self.images_list[0])[0]), desc = 'Loading') as pbar:\n",
        "            i = 0\n",
        "            for batch_number in range(np.shape(self.images_list)[0]):\n",
        "                for images in self.images_list[batch_number]:\n",
        "                    i += 1\n",
        "                    image_number = (\"{}\".format(i)).zfill(5)\n",
        "                    image = Image.fromarray(images)\n",
        "                    image = image.convert('L')\n",
        "                    image.save(\"/content/drive/My Drive/Colab/Data/Train_Data/First_train/{}/{}_{}.jpg\".format(self.mode, list_num, image_number), 'JPEG')\n",
        "                    #clean_image = images/255.0\n",
        "                    #noise_image = clean_image + tf.random.poisson(clean_image.shape, 0.5)\n",
        "                    #save_img(clean_image, 32, 32, self.list_num, image_number, mode = 'Noise')\n",
        "                    #save_img(noise_image, 32, 32, image_number, mode = 'Noise')\n",
        "                    pbar.update(1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbQ29ZkEhRGp",
        "outputId": "185f7dea-8b6d-4319-c39e-8179f070564f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "'''root_dir = Dataset_dir + \"/raw_data/data/train/Noise/\"\n",
        "directory = os.listdir(root_dir)\n",
        "i = 0\n",
        "for file in directory:\n",
        "    i += 1\n",
        "    path = os.path.join(root_dir, file)\n",
        "    img = Image.open(path)\n",
        "    img = np.asarray(img)\n",
        "    batches, res = image_to_patches(img, 32, 32)\n",
        "    dataset_make = Dataset_maker(batches, i, 'Noise')\n",
        "    dataset_make.write_img()'''"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'root_dir = Dataset_dir + \"/raw_data/data/train/Noise/\"\\ndirectory = os.listdir(root_dir)\\ni = 0\\nfor file in directory:\\n    i += 1\\n    path = os.path.join(root_dir, file)\\n    img = Image.open(path)\\n    img = np.asarray(img)\\n    batches, res = image_to_patches(img, 32, 32)\\n    dataset_make = Dataset_maker(batches, i, \\'Noise\\')\\n    dataset_make.write_img()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oTfDSz9mdvS"
      },
      "source": [
        "# Image Show Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0iPjc7NQcaP"
      },
      "source": [
        "def noisy_imshow(image, ax=plt):\n",
        "    image = np.asarray(image)\n",
        "    image = (image + 0.5) / 2\n",
        "    image[image < 0] = 0\n",
        "    image[image > 1] = 1\n",
        "    h = ax.imshow(image)\n",
        "    ax.axis('off')\n",
        "    return h"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JWztFqCQdhX"
      },
      "source": [
        "def clean_imshow(image, ax=plt):\n",
        "    image = np.asarray(image)\n",
        "    h = ax.imshow(image)\n",
        "    ax.axis('off')\n",
        "    return h"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsxKOcHBQeTA",
        "outputId": "cb338e20-a610-4b07-ab8f-5eea155b028f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "'''\n",
        "x = train_set[0]\n",
        "fig, axes = plt.subplots(ncols=2)\n",
        "noisy_imshow(x[0], ax=axes[0])\n",
        "axes[0].set_title('Noisy')\n",
        "noisy_imshow(x[1], ax=axes[1])\n",
        "axes[1].set_title('Clean')\n",
        "print(f'image size is {x[0].shape}.')'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nx = train_set[0]\\nfig, axes = plt.subplots(ncols=2)\\nnoisy_imshow(x[0], ax=axes[0])\\naxes[0].set_title('Noisy')\\nnoisy_imshow(x[1], ax=axes[1])\\naxes[1].set_title('Clean')\\nprint(f'image size is {x[0].shape}.')\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bdDIMbtmnUN"
      },
      "source": [
        "# Data Load Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc_0bFf-nCNe"
      },
      "source": [
        "class Data_Loader():\n",
        "    def __init__(self, root_dir, batch_size, mode):\n",
        "        self.batch_size = batch_size\n",
        "        self.mode = mode\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "    def return_image(self, noise_path, clean_path):\n",
        "        noise_img = tf.io.decode_image(tf.io.read_file(noise_path),channels = 1)\n",
        "        noise_img = tf.cast(noise_img, tf.float32) / 255.0\n",
        "        clean_img = tf.io.decode_image(tf.io.read_file(clean_path),channels = 1)\n",
        "        clean_img = tf.cast(clean_img,tf.float32) / 255.0\n",
        "\n",
        "        return noise_img, clean_img\n",
        "\n",
        "    def return_test_image(self, noise_path, clean_path):\n",
        "        noise_img = tf.io.decode_image(tf.io.read_file(noise_path),channels = 1)\n",
        "        noise_img = tf.cast(noise_img, tf.float32) / 255.0\n",
        "        clean_img = tf.io.decode_image(tf.io.read_file(clean_path),channels = 1)\n",
        "        clean_img = tf.cast(clean_img,tf.float32) / 255.0\n",
        "\n",
        "        return noise_img, clean_img\n",
        "    \n",
        "    def Make_Dataset(self):\n",
        "        xy_list = ['Noise', 'Clean']\n",
        "        if self.mode == 'train':\n",
        "            for path in xy_list:\n",
        "                if path == 'Noise':\n",
        "                    noise_dir = os.path.join(self.root_dir, self.mode, path)\n",
        "                    noise_train_path = sorted(glob(noise_dir + '/*.jpg'))\n",
        "                elif path == 'Clean':\n",
        "                    clean_dir = os.path.join(self.root_dir, self.mode, path)\n",
        "                    clean_train_path = sorted(glob(clean_dir + '/*.jpg'))\n",
        "            dataset = tf.data.Dataset.from_tensor_slices((noise_train_path, clean_train_path))\n",
        "            dataset = dataset.map(self.return_image)\n",
        "            dataset = dataset.batch(self.batch_size)\n",
        "            dataset = dataset.shuffle(buffer_size = len(noise_train_path))\n",
        "\n",
        "        elif self.mode == 'test':\n",
        "            for path in xy_list:\n",
        "                if path == 'Noise':\n",
        "                    noise_dir = os.path.join(self.root_dir, self.mode, path)\n",
        "                    noise_test_path = sorted(glob(noise_dir + '/*.jpg'))\n",
        "                    print(noise_test_path)\n",
        "                elif path == 'Clean':\n",
        "                    clean_dir = os.path.join(self.root_dir, self.mode, path)\n",
        "                    clean_test_path = sorted(glob(clean_dir + '/*.jpg'))\n",
        "            dataset = tf.data.Dataset.from_tensor_slices((noise_test_path, clean_test_path))\n",
        "            dataset = dataset.map(self.return_test_image)\n",
        "            dataset = dataset.batch(self.batch_size)\n",
        "        \n",
        "        return dataset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkcPcPm2pfvk",
        "outputId": "683db582-ab8f-436f-d31f-ee9a6e1e637c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "Generate_train_ds = Data_Loader('/content/drive/My Drive/Colab/Data/Dataset/', 16, mode = 'train')\n",
        "data = Generate_train_ds.Make_Dataset()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3350: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-de1099264c4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mGenerate_train_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_Loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab/Data/Dataset/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerate_train_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMake_Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-9e83ecb67509>\u001b[0m in \u001b[0;36mMake_Dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m                     \u001b[0mclean_train_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclean_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_train_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_train_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_train_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \"\"\"\n\u001b[1;32m   1694\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m       return ParallelMapDataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4043\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4044\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4045\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   4046\u001b[0m     variant_tensor = gen_dataset_ops.map_dataset(\n\u001b[1;32m   4047\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3369\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3370\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3371\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3373\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2937\u001b[0m     \"\"\"\n\u001b[1;32m   2938\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 2939\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2904\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2905\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2906\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2907\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2908\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3362\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   3363\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3364\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3365\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   3297\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m       \u001b[0;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m       \u001b[0;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    <ipython-input-11-9e83ecb67509>:8 return_image  *\n        noise_img = tf.io.decode_image(tf.io.read_file(noise_path),channels = 1)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_io_ops.py:575 read_file  **\n        \"ReadFile\", filename=filename, name=name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:493 _apply_op_helper\n        (prefix, dtypes.as_dtype(input_arg.type).name))\n\n    TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8KKOyXjUJgm"
      },
      "source": [
        "Generate_test_ds = Data_Loader('/content/drive/My Drive/Colab/Data/Dataset/', 1, mode = 'test')\n",
        "test_data = Generate_test_ds.Make_Dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVDVqOKuBh3d"
      },
      "source": [
        "#data_y[0]: noise/clean\n",
        "#data_y[0][:]: batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_SsAAkqQg-o"
      },
      "source": [
        "class input_conv_layer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(input_conv_layer, self).__init__()\n",
        "        self.conv = tf.keras.layers.Conv2D(64, (3,3), padding = 'same')\n",
        "        self.relu = tf.keras.layers.ReLU()\n",
        "        \n",
        "    def call(self, x, training=False, mask=None):\n",
        "        return self.relu(self.conv(x))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1MRDYXmQmkQ"
      },
      "source": [
        "class skip_layer(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(skip_layer, self).__init__()\n",
        "        self.conv = tf.keras.layers.Conv2D(3, (3,3), padding = 'same')\n",
        "        self.relu = tf.keras.layers.ReLU()\n",
        "    \n",
        "    def call(self, x, training = False, mask=None):\n",
        "        return self.relu(self.conv(x))"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IVYF6H2i1A5"
      },
      "source": [
        "class Multi_LSTM(tf.keras.layers.Layer):\n",
        "    def __init__(self):\n",
        "        super(Multi_LSTM, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, (1,1), padding = 'same')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(32, (1,1), padding = 'same')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(1, (1,3), padding = 'same')\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "    \n",
        "    def concat(self, x):\n",
        "        # x : 256 1 32 32\n",
        "        concat_list = []\n",
        "        for i in range(tf.shape(x)[3]):\n",
        "            flat = tf.expand_dims(self.flatten(x[:,:,:,i]), axis = 1) # 256 1 32\n",
        "            inputs = tf.shape(x)[1] * tf.shape(x)[2]\n",
        "            mini_LSTM = tf.expand_dims(tf.keras.layers.GRU(inputs)(flat), -1) # 256 32 1\n",
        "            concat_list.append(mini_LSTM)\n",
        "        LSTM = tf.keras.layers.concatenate(concat_list, axis = -1) #256 32 32\n",
        "\n",
        "        return LSTM\n",
        "        \n",
        "    def call(self, x, training = False, mask = None):\n",
        "        h = self.conv3(x) # 256 32 32 1\n",
        "        rot_0 = (tf.expand_dims(h, axis=1))[:,:,:,:,-1] #256 1 32 32 \n",
        "        rot_90 = (tf.expand_dims(tf.image.rot90(h, k=1), axis=1))[:,:,:,:,-1]\n",
        "        rot_180 = (tf.expand_dims(tf.image.rot90(h, k=2), axis=1))[:,:,:,:,-1]\n",
        "        rot_270 = (tf.expand_dims(tf.image.rot90(h, k=3), axis=1))[:,:,:,:,-1]\n",
        "\n",
        "        LSTM_0 = tf.expand_dims(self.concat(rot_0), axis = -1) #256 32 32 1\n",
        "        LSTM_90 = tf.expand_dims(self.concat(rot_90), axis = -1)\n",
        "        LSTM_180 = tf.expand_dims(self.concat(rot_180), axis = -1)\n",
        "        LSTM_270 = tf.expand_dims(self.concat(rot_270), axis = -1)\n",
        "\n",
        "        h_concat = tf.keras.layers.concatenate([LSTM_0, LSTM_90, LSTM_180, LSTM_270], axis = -1)\n",
        "        h_concat = self.conv1(h_concat)\n",
        "\n",
        "        return h_concat"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCQbGtF7QoTv"
      },
      "source": [
        "class DeN_Model(tf.keras.Model):\n",
        "    def __init__(self, channel = 64, DCNN_Layer = 15):\n",
        "        super(DeN_Model, self).__init__()\n",
        "        self.input_conv = [input_conv_layer() for _ in range(DCNN_Layer)]\n",
        "        self.skip = [skip_layer() for _ in range(DCNN_Layer)]\n",
        "        self.lstm_list1 = Multi_LSTM()\n",
        "        self.lstm_list2 = Multi_LSTM()\n",
        "        self.lstm_list3 = Multi_LSTM()\n",
        "        self.next_skip1 = skip_layer()\n",
        "        self.next_skip2 = skip_layer()\n",
        "        self.next_skip3 = skip_layer()\n",
        "        self.conv_1 = tf.keras.layers.Conv2D(1, (3,3), padding = 'same')\n",
        "    \n",
        "    def call(self, x, training = False, mask = None):\n",
        "        print('Epoch Start')\n",
        "        input_img = x\n",
        "        h_return = 0\n",
        "        for layer in range(15):\n",
        "            h = self.input_conv[layer](x, training) #256 32 32 64\n",
        "            h_skip = self.skip[layer](h, training) # 256 32 32 3\n",
        "            h_skip = self.conv_1(h_skip) #256 32 32 1\n",
        "            h_return = h_return + h_skip # 256 32 32 1\n",
        "        \n",
        "        #identity_h = tf.keras.layers.ReLU(tf.identity(h))\n",
        "        start_time = time.time()\n",
        "        print('LSTM Start time: {}'.format(start_time))\n",
        "\n",
        "        h = self.lstm_list1(h) # 256 32 32 64\n",
        "        h_skip = self.next_skip1(h, training) #256 32 32 3\n",
        "        h_skip = self.conv_1(h_skip) #256 32 32 1\n",
        "        h_return = h_return + h_skip\n",
        "\n",
        "        print('Duration: {}'.format(time.time() - start_time))\n",
        "\n",
        "        '''\n",
        "        h = self.lstm_list2(h)\n",
        "        h_skip = self.next_skip2(h, training)\n",
        "        h_skip = self.conv_1(h_skip)\n",
        "        h_return = h_return + h_skip\n",
        "        \n",
        "        h = self.lstm_list3(h)\n",
        "        h_skip = self.next_skip3(h, training)\n",
        "        h_skip = self.conv_1(h_skip) #256 32 32 1\n",
        "\n",
        "        h_return = h_return + h_skip\n",
        "        '''\n",
        "\n",
        "        output = tf.keras.layers.subtract([input_img, h_return])\n",
        "\n",
        "        return output"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNcjn5HebkJg"
      },
      "source": [
        "initial_learning_rate = 1e-3\n",
        "#Ir_schedule = tf.keras.optimizers.schedules.ExponentialDecay(initial_learning_rate,decay_steps = 16,decay_rate = 0.5,staircase = True)\n",
        "\n",
        "optimizer = tf.optimizers.Adam(initial_learning_rate)\n",
        "Model = DeN_Model()\n",
        "\n",
        "\n",
        "Model.compile(optimizer = optimizer, loss = 'mae')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvM-bUcIzKuC"
      },
      "source": [
        "Model.load_weights('/content/drive/My Drive/Colab/my_checkpoint/007/')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGwE7rHa1uOP"
      },
      "source": [
        "checkpoint_path = '/content/drive/My Drive/Colab/my_checkpoint/007/'\n",
        "\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "\n",
        "callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_path,\n",
        "    verbose = 1,\n",
        "    save_weights_only = False,\n",
        "    save_freq = 16)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPIHMDENcIeJ",
        "outputId": "c13361f1-23fb-457f-a45d-821711af7910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Model.fit(data, steps_per_epoch=72, epochs = 10, callbacks = [callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMofXBpZggkb"
      },
      "source": [
        "for noise, clean in test_data:\n",
        "    denoised = Model(noise)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW0rz1OHsCB_"
      },
      "source": [
        "ns, cl = next(iter(test_data))\n",
        "img = np.concatenate([ns[0], cl[0]], axis = 1)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y_p2_EUhAX8"
      },
      "source": [
        "np.max(denoised[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx7o775w5sP0"
      },
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "plt.imshow(np.concatenate([im, cl_im, denoised[0]], axis = 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2E__lym04X-"
      },
      "source": [
        "print('Complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_AFAdtMb-9_"
      },
      "source": [
        "#Model_R.save_weights('/content/drive/My Drive/Colab/my_checkpoint/002/Red/')\n",
        "#Model_G.save_weights('/content/drive/My Drive/Colab/my_checkpoint/002/Green/')\n",
        "#Model_B.save_weights('/content/drive/My Drive/Colab/my_checkpoint/002/Blue/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZqU3cf9crLB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}